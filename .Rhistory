rettype="fasta", retmax=50, retstart=seq_start[j])
cat(recs, file="./TestFolder/Otidea_loop5.fasta", append=TRUE)
if(j < batch_n){
cat("\n",seq_start[j]+49, "sequences downloaded\r")
}else{
cat("\n", max_seq, "sequences downloaded\r")
}
}
}
}else{
cat("\n#\n#This  taxon does not have data in the nuccore db:\n")
}
}else{
cat("\n#\n#Skipping uncultured sources db:\n")
}
}
set_entrez_key(api_key)
r_search <- entrez_search(db = "taxonomy",
term = paste0("\"", search_term, "\"", "[Organism] OR ",
search_term, "[All Fields]"),
retmax = 999,
use_history = TRUE) # gets all IDs for genus
ID_n <- length(r_search$ids) # reducing repetitions by reusing this variable
ID <- r_search$ids
for(i in 1:ID_n){
taxon <- entrez_fetch(db="taxonomy", id = ID[i], rettype = "text")
taxon <- unlist(str_split(taxon, "\n"))[1]
cat("\nID ", i, ":\t", ID[i], "\t", taxon, "\t")
if(!str_detect(taxon, "uncultured")){
upload <- entrez_post(db = "taxonomy",
id = ID[i])
link_history <- entrez_link(dbfrom = "taxonomy",
db = "nuccore",
web_history = upload,
cmd = "neighbor_history") # store neighbor history on NCBI server in other words I don't download the linked IDs but store them as a web history
if(!is.null(link_history$web_histories$taxonomy_nuccore)){
summary_result <- entrez_summary("nuccore",
web_history = link_history$web_histories$taxonomy_nuccore)
if(names(summary_result)[1] == "uid"){ # with this I check if I have just 1 sequence, so the first element should be "uid", if not, multiple records need to be downloaded
key_info <- c(summary_result$uid, summary_result$oslt$value, summary_result$slen)
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta")
cat(recs, file="./TestFolder/Otidea_loop5.fasta", append=TRUE)
}else{
key_info2 <- lapply(summary_result, function(x) c(x$uid, x$oslt$value, x$slen))
max_seq <- length(key_info2)
seq_start <- seq(1,max_seq,50)
batch_n <- length(seq_start)
for(j in 1:batch_n){
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta", retmax=50, retstart=seq_start[j])
cat(recs, file="./TestFolder/Otidea_loop5.fasta", append=TRUE)
if(j < batch_n){
cat("\n",seq_start[j]+49, "sequences downloaded\r")
}else{
cat("\n", max_seq, "sequences downloaded\r")
}
}
}
}else{
cat("\n#\n#This  taxon does not have data in the nuccore db:\n")
}
}else{
cat("\n#\n#Skipping uncultured sources db:\n")
}
}
seqs5 <- read.fasta("./TestFolder/Otidea_loop5.fasta")
extr_id <- names(seqs5)[!names(seqs5) %in% names(seqs)]
extra_seqs <- seqs5[extr_id]
getAnnot(extra_seqs[[1]])
write.fasta(extra_seqs, names = getAnnot(extra_seqs), file.out = "./TestFolder/extra_seq.fasta")
extr_id2 <- names(seqs5)[!names(seqs) %in% names(seqs5)]
NCBI_search <- readline("./TestFolder/nuccore_result.txt")
NCBI_search <- read.fasta("./TestFolder/sequence.fasta")
extr_id <- names(NCBI_search)[!names(NCBI_search) %in% names(seqs)]
extra_seqs <- NCBI_search[extr_id]
write.fasta(extra_seqs, names = getAnnot(extra_seqs), file.out = "./TestFolder/extra_seq.fasta")
recs <- entrez_fetch(db="nuccore", id = "NR_182423",
rettype="fasta")
recs
r_search <- entrez_search(db = "taxonomy",
term = "Otidea shennongjiana",
retmax = 999,
use_history = TRUE) # gets all IDs for genus
ID_n <- length(r_search$ids) # reducing repetitions by reusing this variable
ID <- r_search$ids
i <- 1
taxon <- entrez_fetch(db="taxonomy", id = ID[i], rettype = "text")
taxon <- entrez_fetch(db="taxonomy", id = ID[i], rettype = "text")
taxon <- unlist(str_split(taxon, "\n"))[1]
cat("\nID ", i, ":\t", ID[i], "\t", taxon, "\t")
upload <- entrez_post(db = "taxonomy",
id = ID[i])
link_history <- entrez_link(dbfrom = "taxonomy",
db = "nuccore",
web_history = upload,
cmd = "neighbor_history") # store neighbor history on NCBI server in other words I don't download the linked IDs but store them as a web history
!is.null(link_history$web_histories$taxonomy_nuccore)
summary_result <- entrez_summary("nuccore",
web_history = link_history$web_histories$taxonomy_nuccore)
key_info2 <- lapply(summary_result, function(x) c(x$uid, x$oslt$value, x$slen))
max_seq <- length(key_info2)
seq_start <- seq(1,max_seq,50)
batch_n <- length(seq_start)
for(j in 1:batch_n){
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta", retmax=50, retstart=seq_start[j])
cat(recs, file="./TestFolder/Otidea_shennongjiana.fasta", append=TRUE)
if(j < batch_n){
cat("\n",seq_start[j]+49, "sequences downloaded\r")
}else{
cat("\n", max_seq, "sequences downloaded\r")
}
}
key_info2
seq_start[j]
seq_start[j]-1
key_info2
for(j in 1:batch_n){
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta", retmax=50, retstart=seq_start[j]-1)
cat(recs, file="./TestFolder/Otidea_shennongjiana.fasta", append=TRUE)
if(j < batch_n){
cat("\n",seq_start[j]+49, "sequences downloaded\r")
}else{
cat("\n", max_seq, "sequences downloaded\r")
}
}
for(j in 1:batch_n){
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta", retmax=50, retstart=seq_start[j]-1)
cat(recs, file="./TestFolder/Otidea_shennongjiana.fasta", append=TRUE)
if(j < batch_n){
cat("\n",seq_start[j]+49, "sequences downloaded\r")
}else{
cat("\n", max_seq, "sequences downloaded\r")
}
}
set_entrez_key(api_key)
r_search <- entrez_search(db = "taxonomy",
term = paste0(search_term, "[subtree]"),
retmax = 999,
use_history = TRUE) # gets all IDs for genus
ID_n <- length(r_search$ids) # reducing repetitions by reusing this variable
ID <- r_search$ids
for(i in 1:ID_n){
taxon <- entrez_fetch(db="taxonomy", id = ID[i], rettype = "text")
taxon <- unlist(str_split(taxon, "\n"))[1]
cat("\nID ", i, ":\t", ID[i], "\t", taxon, "\t")
if(!str_detect(taxon, "uncultured")){
upload <- entrez_post(db = "taxonomy",
id = ID[i])
link_history <- entrez_link(dbfrom = "taxonomy",
db = "nuccore",
web_history = upload,
cmd = "neighbor_history") # store neighbor history on NCBI server in other words I don't download the linked IDs but store them as a web history
if(!is.null(link_history$web_histories$taxonomy_nuccore)){
summary_result <- entrez_summary("nuccore",
web_history = link_history$web_histories$taxonomy_nuccore)
if(names(summary_result)[1] == "uid"){ # with this I check if I have just 1 sequence, so the first element should be "uid", if not, multiple records need to be downloaded
key_info <- c(summary_result$uid, summary_result$oslt$value, summary_result$slen)
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta")
cat(recs, file="./TestFolder/Otidea_loop5.fasta", append=TRUE)
}else{
key_info2 <- lapply(summary_result, function(x) c(x$uid, x$oslt$value, x$slen))
max_seq <- length(key_info2)
seq_start <- seq(1,max_seq,50)
batch_n <- length(seq_start)
for(j in 1:batch_n){
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta", retmax=50, retstart=seq_start[j]-1)
cat(recs, file="./TestFolder/Otidea_loop5.fasta", append=TRUE)
if(j < batch_n){
cat("\n",seq_start[j]+49, "sequences downloaded\r")
}else{
cat("\n", max_seq, "sequences downloaded\r")
}
}
}
}else{
cat("\n#\n#This  taxon does not have data in the nuccore db:\n")
}
}else{
cat("\n#\n#Skipping uncultured sources db:\n")
}
}
set_entrez_key(api_key)
r_search <- entrez_search(db = "taxonomy",
term = paste0(search_term, "[subtree]"),
retmax = 999,
use_history = TRUE) # gets all IDs for genus
ID_n <- length(r_search$ids) # reducing repetitions by reusing this variable
ID <- r_search$ids
for(i in 1:ID_n){
taxon <- entrez_fetch(db="taxonomy", id = ID[i], rettype = "text")
taxon <- unlist(str_split(taxon, "\n"))[1]
cat("\nID ", i, ":\t", ID[i], "\t", taxon, "\t")
if(!str_detect(taxon, "uncultured")){
upload <- entrez_post(db = "taxonomy",
id = ID[i])
link_history <- entrez_link(dbfrom = "taxonomy",
db = "nuccore",
web_history = upload,
cmd = "neighbor_history") # store neighbor history on NCBI server in other words I don't download the linked IDs but store them as a web history
if(!is.null(link_history$web_histories$taxonomy_nuccore)){
summary_result <- entrez_summary("nuccore",
web_history = link_history$web_histories$taxonomy_nuccore)
if(names(summary_result)[1] == "uid"){ # with this I check if I have just 1 sequence, so the first element should be "uid", if not, multiple records need to be downloaded
key_info <- c(summary_result$uid, summary_result$oslt$value, summary_result$slen)
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta")
cat(recs, file="./TestFolder/Otidea_loop6.fasta", append=TRUE)
}else{
key_info2 <- lapply(summary_result, function(x) c(x$uid, x$oslt$value, x$slen))
max_seq <- length(key_info2)
seq_start <- seq(1,max_seq,50)
batch_n <- length(seq_start)
for(j in 1:batch_n){
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta", retmax=50, retstart=seq_start[j]-1)
cat(recs, file="./TestFolder/Otidea_loop6.fasta", append=TRUE)
if(j < batch_n){
cat("\n",seq_start[j]+49, "sequences downloaded\r")
}else{
cat("\n", max_seq, "sequences downloaded\r")
}
}
}
}else{
cat("\n#\n#This  taxon does not have data in the nuccore db:\n")
}
}else{
cat("\n#\n#Skipping uncultured sources db:\n")
}
}
set_entrez_key(api_key)
r_search <- entrez_search(db = "taxonomy",
term = paste0(search_term, "[subtree]"),
retmax = 999,
use_history = TRUE) # gets all IDs for genus
ID_n <- length(r_search$ids) # reducing repetitions by reusing this variable
ID <- r_search$ids
for(i in 1:ID_n){
taxon <- entrez_fetch(db="taxonomy", id = ID[i], rettype = "text")
taxon <- unlist(str_split(taxon, "\n"))[1]
cat("\nID ", i, ":\t", ID[i], "\t", taxon, "\t")
if(!str_detect(taxon, "uncultured")){
upload <- entrez_post(db = "taxonomy",
id = ID[i])
link_history <- entrez_link(dbfrom = "taxonomy",
db = "nuccore",
web_history = upload,
cmd = "neighbor_history") # store neighbor history on NCBI server in other words I don't download the linked IDs but store them as a web history
if(!is.null(link_history$web_histories$taxonomy_nuccore)){
summary_result <- entrez_summary("nuccore",
web_history = link_history$web_histories$taxonomy_nuccore)
if(names(summary_result)[1] == "uid"){ # with this I check if I have just 1 sequence, so the first element should be "uid", if not, multiple records need to be downloaded
key_info <- c(summary_result$uid, summary_result$oslt$value, summary_result$slen)
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta")
cat(recs, file="./TestFolder/Otidea_loop6.fasta", append=TRUE)
}else{
key_info2 <- lapply(summary_result, function(x) c(x$uid, x$oslt$value, x$slen))
max_seq <- length(key_info2)
seq_start <- seq(1,max_seq,50)
batch_n <- length(seq_start)
for(j in 1:batch_n){
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta", retmax=50, retstart=seq_start[j]-1)
cat(recs, file="./TestFolder/Otidea_loop6.fasta", append=TRUE)
if(j < batch_n){
cat("\n",seq_start[j]+49, "sequences downloaded\r")
}else{
cat("\n", max_seq, "sequences downloaded\r")
}
}
}
}else{
cat("\n#\n#This  taxon does not have data in the nuccore db:\n")
}
}else{
cat("\n#\n#Skipping uncultured sources db:\n")
}
}
set_entrez_key("ce946cc5385e86927f230c4aea4a5f68ac08")
r_search <- entrez_search(db = "taxonomy",
term = paste0(search_term, "[subtree]"),
retmax = 999,
use_history = TRUE) # gets all IDs for genus
ID_n <- length(r_search$ids) # reducing repetitions by reusing this variable
ID <- r_search$ids
for(i in 1:ID_n){
taxon <- entrez_fetch(db="taxonomy", id = ID[i], rettype = "text")
taxon <- unlist(str_split(taxon, "\n"))[1]
cat("\nID ", i, ":\t", ID[i], "\t", taxon, "\t")
if(!str_detect(taxon, "uncultured")){
upload <- entrez_post(db = "taxonomy",
id = ID[i])
link_history <- entrez_link(dbfrom = "taxonomy",
db = "nuccore",
web_history = upload,
cmd = "neighbor_history") # store neighbor history on NCBI server in other words I don't download the linked IDs but store them as a web history
if(!is.null(link_history$web_histories$taxonomy_nuccore)){
summary_result <- entrez_summary("nuccore",
web_history = link_history$web_histories$taxonomy_nuccore)
if(names(summary_result)[1] == "uid"){ # with this I check if I have just 1 sequence, so the first element should be "uid", if not, multiple records need to be downloaded
key_info <- c(summary_result$uid, summary_result$oslt$value, summary_result$slen)
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta")
cat(recs, file="./TestFolder/Otidea_loop6.fasta", append=TRUE)
}else{
key_info2 <- lapply(summary_result, function(x) c(x$uid, x$oslt$value, x$slen))
max_seq <- length(key_info2)
seq_start <- seq(1,max_seq,50)
batch_n <- length(seq_start)
for(j in 1:batch_n){
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta", retmax=50, retstart=seq_start[j]-1)
cat(recs, file="./TestFolder/Otidea_loop6.fasta", append=TRUE)
if(j < batch_n){
cat("\n",seq_start[j]+49, "sequences downloaded\r")
}else{
cat("\n", max_seq, "sequences downloaded\r")
}
}
}
}else{
cat("\n#\n#This  taxon does not have data in the nuccore db:\n")
}
}else{
cat("\n#\n#Skipping uncultured sources db:\n")
}
}
i <- 1
taxon <- entrez_fetch(db="taxonomy", id = ID[i], rettype = "text")
taxon <- unlist(str_split(taxon, "\n"))[1]
cat("\nID ", i, ":\t", ID[i], "\t", taxon, "\t")
upload <- entrez_post(db = "taxonomy",
id = ID[i])
link_history <- entrez_link(dbfrom = "taxonomy",
db = "nuccore",
web_history = upload,
cmd = "neighbor_history") # store neighbor history on NCBI server in other words I don't download the linked IDs but store them as a web history
!is.null(link_history$web_histories$taxonomy_nuccore)
summary_result <- entrez_summary("nuccore",
web_history = link_history$web_histories$taxonomy_nuccore)
names(summary_result)[1] == "uid"
key_info <- c(summary_result$uid, summary_result$oslt$value, summary_result$slen)
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta")
#set_entrez_key("ce946cc5385e86927f230c4aea4a5f68ac08")
r_search <- entrez_search(db = "taxonomy",
term = paste0(search_term, "[subtree]"),
retmax = 999,
use_history = TRUE) # gets all IDs for genus
ID_n <- length(r_search$ids) # reducing repetitions by reusing this variable
ID <- r_search$ids
i <- 1
for(i in 1:ID_n){
taxon <- entrez_fetch(db="taxonomy", id = ID[i], rettype = "text")
taxon <- unlist(str_split(taxon, "\n"))[1]
cat("\nID ", i, ":\t", ID[i], "\t", taxon, "\t")
if(!str_detect(taxon, "uncultured")){
upload <- entrez_post(db = "taxonomy",
id = ID[i])
link_history <- entrez_link(dbfrom = "taxonomy",
db = "nuccore",
web_history = upload,
cmd = "neighbor_history") # store neighbor history on NCBI server in other words I don't download the linked IDs but store them as a web history
if(!is.null(link_history$web_histories$taxonomy_nuccore)){
summary_result <- entrez_summary("nuccore",
web_history = link_history$web_histories$taxonomy_nuccore)
if(names(summary_result)[1] == "uid"){ # with this I check if I have just 1 sequence, so the first element should be "uid", if not, multiple records need to be downloaded
key_info <- c(summary_result$uid, summary_result$oslt$value, summary_result$slen)
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta")
cat(recs, file="./TestFolder/Otidea_loop6.fasta", append=TRUE)
}else{
key_info2 <- lapply(summary_result, function(x) c(x$uid, x$oslt$value, x$slen))
max_seq <- length(key_info2)
seq_start <- seq(1,max_seq,50)
batch_n <- length(seq_start)
for(j in 1:batch_n){
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta", retmax=50, retstart=seq_start[j]-1)
cat(recs, file="./TestFolder/Otidea_loop6.fasta", append=TRUE)
if(j < batch_n){
cat("\n",seq_start[j]+49, "sequences downloaded\r")
}else{
cat("\n", max_seq, "sequences downloaded\r")
}
}
}
}else{
cat("\n#\n#This  taxon does not have data in the nuccore db:\n")
}
}else{
cat("\n#\n#Skipping uncultured sources db:\n")
}
}
for(i in 34:ID_n){
taxon <- entrez_fetch(db="taxonomy", id = ID[i], rettype = "text")
taxon <- unlist(str_split(taxon, "\n"))[1]
cat("\nID ", i, ":\t", ID[i], "\t", taxon, "\t")
if(!str_detect(taxon, "uncultured")){
upload <- entrez_post(db = "taxonomy",
id = ID[i])
link_history <- entrez_link(dbfrom = "taxonomy",
db = "nuccore",
web_history = upload,
cmd = "neighbor_history") # store neighbor history on NCBI server in other words I don't download the linked IDs but store them as a web history
if(!is.null(link_history$web_histories$taxonomy_nuccore)){
summary_result <- entrez_summary("nuccore",
web_history = link_history$web_histories$taxonomy_nuccore)
if(names(summary_result)[1] == "uid"){ # with this I check if I have just 1 sequence, so the first element should be "uid", if not, multiple records need to be downloaded
key_info <- c(summary_result$uid, summary_result$oslt$value, summary_result$slen)
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta")
cat(recs, file="./TestFolder/Otidea_loop6.fasta", append=TRUE)
}else{
key_info2 <- lapply(summary_result, function(x) c(x$uid, x$oslt$value, x$slen))
max_seq <- length(key_info2)
seq_start <- seq(1,max_seq,50)
batch_n <- length(seq_start)
for(j in 1:batch_n){
recs <- entrez_fetch(db="nuccore", web_history=link_history$web_histories$taxonomy_nuccore,
rettype="fasta", retmax=50, retstart=seq_start[j]-1)
cat(recs, file="./TestFolder/Otidea_loop6.fasta", append=TRUE)
if(j < batch_n){
cat("\n",seq_start[j]+49, "sequences downloaded\r")
}else{
cat("\n", max_seq, "sequences downloaded\r")
}
}
}
}else{
cat("\n#\n#This  taxon does not have data in the nuccore db:\n")
}
}else{
cat("\n#\n#Skipping uncultured sources db:\n")
}
}
seqs6 <- read.fasta("./TestFolder/Otidea_loop6.fasta")
extr_id <- names(NCBI_search)[!names(NCBI_search) %in% names(seqs6)]
extra_seqs <- NCBI_search[extr_id]
write.fasta(extra_seqs, names = getAnnot(extra_seqs), file.out = "./TestFolder/extra_seq2.fasta")
i <- 66
upload <- entrez_post(db = "taxonomy",
id = ID[i])
link_history <- entrez_link(dbfrom = "taxonomy",
db = "popset",
web_history = upload,
cmd = "neighbor_history") # store neighbor history on NCBI server in other words I don't download the linked IDs but store them as a web history
summary_result <- entrez_summary("popset", web_history = link_history$web_histories$taxonomy_popset)
r_search <- entrez_search(db = "taxonomy",
term = paste0(search_term, "[subtree]"),
retmax = 999,
use_history = TRUE) # gets all IDs for genus
ID_n <- length(r_search$ids) # reducing repetitions by reusing this variable
ID <- r_search$ids
# i <- 66
for(i in 1:ID_n){
taxon <- entrez_fetch(db="taxonomy", id = ID[i], rettype = "text")
cat("\nID ", i, ":\t", ID[i], "\t", taxon, "\t")
upload <- entrez_post(db = "taxonomy",
id = ID[i])
link_history <- entrez_link(dbfrom = "taxonomy",
db = "popset",
web_history = upload,
cmd = "neighbor_history") # store neighbor history on NCBI server in other words I don't download the linked IDs but store them as a web history
if(!is.null(link_history$web_histories$taxonomy_popset)){
summary_result <- entrez_summary("popset", web_history = link_history$web_histories$taxonomy_popset)
if(names(summary_result)[1] == "uid"){ # with this I check if I have just 1 sequence, so the first element should be "uid", if not, multiple records need to be downloaded
key_info <- c(summary_result$uid, summary_result$oslt$value, summary_result$slen)
recs <- entrez_fetch(db="popset", web_history=link_history$web_histories$taxonomy_popset,
rettype="fasta")
cat(recs, file="./TestFolder/Otidea_loop_popset.fasta", append=TRUE)
}else{
key_info2 <- lapply(summary_result, function(x) c(x$uid, x$oslt$value, x$slen))
max_seq <- length(key_info2)
seq_start <- seq(1,max_seq,50)
batch_n <- length(seq_start)
for(j in 1:batch_n){
recs <- entrez_fetch(db="popset", web_history=link_history$web_histories$taxonomy_popset,
rettype="fasta", retmax=50, retstart=seq_start[j])
cat(recs, file="./TestFolder/Otidea_loop_popset.fasta", append=TRUE)
if(j < batch_n){
cat("\n",seq_start[j]+49, "sequences downloaded\r")
}else{
cat("\n", max_seq, "sequences downloaded\r")
}
}
}
}else{
cat("\n#\n#This  taxon does not have data in the popset db\n")
}
}
# compare to popset
postet <- read.fasta("./TestFolder/Otidea_loop_popset.fasta")
extr_id2 <- names(extra_seqs)[!names(extra_seqs) %in% names(postet)]
names(extra_seqs)
otidea_popset <- names(postet)[str_detect(getAnnot(postet), "Otidea")]
write.fasta(otidea_popset, names = getAnnot(otidea_popset), file.out = "./TestFolder/otidea_popset.fasta")
otdea_popset_seq <- postet[otidea_popset]
write.fasta(otdea_popset_seq, names = getAnnot(otidea_popset), file.out = "./TestFolder/otidea_popset.fasta")
write.fasta(otdea_popset_seq, names = getAnnot(otdea_popset_seq), file.out = "./TestFolder/otidea_popset.fasta")
extr_id3 <- names(otdea_popset_seq)[!names(otdea_popset_seq) %in% names(seqs6)]
unique(names(otdea_popset_seq))
uniques <- unique(names(otdea_popset_seq))
otidea_popset2 <- names(postet)[str_detect(getAnnot(postet), "otidea")]
otidea_popset2
